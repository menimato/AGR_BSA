{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT 05: Extract Samples Values\n",
    "\n",
    "This is the fifth script in the methodology. Here, the values for the selected samples are extracted and samples files are generated. This can only be done after creating grids with possible samples with SCRIPT 04, and manually selecting appropriate samples locations in a GIS software by comparing the reference created in SCRIPT 03 with images and time series.\n",
    "\n",
    "In the following cells, please refer to the comments in the code for further explanations of its functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import rasterio as r\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample related predefinitions\n",
    "chip_size = 254 # the width and height of every sample\n",
    "total_overlap = 186 # the overlap between each sample (equals to the difference between\n",
    "                    # the sample size and the prediction size)\n",
    "side_overlap = int(total_overlap/2) # overlap on each side\n",
    "chip_util_size = chip_size-total_overlap # the output size. depends on the network.\n",
    "\n",
    "samples_id = '5K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the edited possible samples (they must all be merged in one file)\n",
    "# here the format GPKG is used, but shapefiles are also compatible, just change the 'driver' parameter\n",
    "shp = gpd.read_file('/home/bruno.matosak/Semiarido/MultiInput/samples/shp_possible_samples_edited/samples_location.gpkg', driver='GPKG')\n",
    "shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the filtered samples to extract\n",
    "shp = shp[shp['to_use']==1]\n",
    "print(f'Total samples: {len(shp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling samples\n",
    "shp = shp.sample(frac=1)\n",
    "shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring reference data\n",
    "reference = np.zeros([len(shp), chip_util_size, chip_util_size], dtype = np.byte)\n",
    "\n",
    "# looping through every sample and acquiring its reference\n",
    "for i in tqdm(range(len(shp))):\n",
    "    # open the reference file\n",
    "    raster_dataframe = r.open(f'/home/bruno.matosak/Semiarido/MultiInput/segmentations/GEM_id{str(shp.tile_id.values[i]).zfill(3)}.tif')\n",
    "    # saving it to the variable 'reference'\n",
    "    reference[i] = raster_dataframe.read(1, window=r.windows.Window(shp.ori_col.values[i]+side_overlap,\n",
    "                                                                    shp.ori_row.values[i]+side_overlap,\n",
    "                                                                    chip_util_size, \n",
    "                                                                    chip_util_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the percentage of agriculture distribution in the samples\n",
    "\n",
    "# percentage of agriculture per sample\n",
    "per = np.zeros([len(shp)], dtype=np.float32)\n",
    "for i in range(len(shp)):\n",
    "    per[i] = 100*np.sum(reference[i])/(chip_util_size**2)\n",
    "\n",
    "plt.hist(per, bins=10)\n",
    "plt.title('Histogram of Agriculture Percentage Per Sample')\n",
    "plt.xlabel('Percentage (%)')\n",
    "plt.ylabel('Qt. of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrating samples image data\n",
    "\n",
    "# define placeholder for the samples\n",
    "# yearly data\n",
    "samples_s1_y = np.zeros([len(shp), chip_size, chip_size, 2], dtype=np.int16)\n",
    "samples_s2_y = np.zeros([len(shp), chip_size, chip_size, 6], dtype=np.int16)\n",
    "# monthly data\n",
    "samples_s1_m = np.zeros([len(shp), 12, chip_size, chip_size, 2], dtype=np.int16)\n",
    "samples_s2_m = np.zeros([len(shp), 12, chip_size, chip_size, 6], dtype=np.int16)\n",
    "\n",
    "# bands\n",
    "bands_s1 = ['VV', 'VH']\n",
    "bands_s2 = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "\n",
    "# looping through every sample\n",
    "for i in tqdm(range(len(shp))):\n",
    "    # the sample origin\n",
    "    ori_row = shp.ori_row.values[i]\n",
    "    ori_col = shp.ori_col.values[i]\n",
    "    \n",
    "    # acquiring yearly data\n",
    "    samples_s1_y[i] = np.moveaxis(r.open(f'/home/bruno.matosak/Semiarido/MultiInput/yearly_reduction_S1/Reduction_SAR_Year_id{str(shp.tile_id.values[i]).zfill(3)}.tif').read(window=r.windows.Window(ori_col, ori_row, chip_size, chip_size)), 0, -1)\n",
    "    samples_s2_y[i] = np.moveaxis(r.open(f'/home/bruno.matosak/Semiarido/MultiInput/yearly_reduction_S2/Reduction_Optical_Year_id{str(shp.tile_id.values[i]).zfill(3)}.tif').read(window=r.windows.Window(ori_col, ori_row, chip_size, chip_size)), 0, -1)\n",
    "    \n",
    "    # acquiring monthly data\n",
    "    for ii in range(len(bands_s1)):\n",
    "        samples_s1_m[i, :, :, :, ii] = r.open(f'/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S1/Reduction_SAR_Months_id{str(shp.tile_id.values[i]).zfill(3)}_{bands_s1[ii]}.tif').read(window=r.windows.Window(ori_col, ori_row, chip_size, chip_size))\n",
    "    \n",
    "    for ii in range(len(bands_s2)):\n",
    "        samples_s2_m[i, :, :, :, ii] = r.open(f'/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(shp.tile_id.values[i]).zfill(3)}_{bands_s2[ii]}.tif').read(window=r.windows.Window(ori_col, ori_row, chip_size, chip_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving unmodified samples\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_RAW_reference.npy', reference)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_RAW_s1_y.npy', samples_s1_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_RAW_s2_y.npy', samples_s2_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_RAW_s1_m.npy', samples_s1_m)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_RAW_s2_m.npy', samples_s2_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing samples to be used by scaling them between 0 and 1.\n",
    "# this is done using the 1% and 99% limits of the data (ignoring\n",
    "# masked areas). the limits are stored in files that are needed later\n",
    "# during the prediction in order to correctly scale data used to\n",
    "# generate the full map.\n",
    "\n",
    "# reference to categorical\n",
    "reference_cat = to_categorical(reference)\n",
    "\n",
    "# functions to find the 1% bottom and top most limits of data\n",
    "def get_limits(data):\n",
    "    return np.nanpercentile(data, q=[1,99])\n",
    "\n",
    "# placeholder for the limits to adjust the data\n",
    "limits_s1_y = np.zeros([len(bands_s1), 2], dtype=np.float32)\n",
    "limits_s2_y = np.zeros([len(bands_s2), 2], dtype=np.float32)\n",
    "limits_s1_m = np.zeros([len(bands_s1), 2], dtype=np.float32)\n",
    "limits_s2_m = np.zeros([len(bands_s2), 2], dtype=np.float32)\n",
    "\n",
    "# converting the typer of data\n",
    "samples_s1_y = np.asarray(samples_s1_y, dtype=np.float32)\n",
    "samples_s1_y[samples_s1_y==0] = None\n",
    "samples_s2_y = np.asarray(samples_s2_y, dtype=np.float32)\n",
    "samples_s2_y[samples_s2_y==0] = None\n",
    "samples_s1_m = np.asarray(samples_s1_m, dtype=np.float32)\n",
    "samples_s1_m[samples_s1_m==0] = None\n",
    "samples_s2_m = np.asarray(samples_s2_m, dtype=np.float32)\n",
    "samples_s2_m[samples_s2_m==0] = None\n",
    "\n",
    "# loop to scale Sentinel-1 data reductions\n",
    "for i in tqdm(range(len(bands_s1))):\n",
    "    limits_s1_y[i] = get_limits(samples_s1_y[:, :, :, i])\n",
    "    samples_s1_y[:, :, :, i] = (samples_s1_y[:, :, :, i]-limits_s1_y[i, 0])/(limits_s1_y[i, 1]-limits_s1_y[i, 0])\n",
    "    \n",
    "    limits_s1_m[i] = get_limits(samples_s1_m[:, :, :, :, i])\n",
    "    samples_s1_m[:, :, :, :, i] = (samples_s1_m[:, :, :, :, i]-limits_s1_m[i, 0])/(limits_s1_m[i, 1]-limits_s1_m[i, 0])\n",
    "\n",
    "# loop to scale Sentinel-2 data reductions\n",
    "for i in tqdm(range(len(bands_s2))):\n",
    "    limits_s2_y[i] = get_limits(samples_s2_y[:, :, :, i])\n",
    "    samples_s2_y[:, :, :, i] = (samples_s2_y[:, :, :, i]-limits_s2_y[i, 0])/(limits_s2_y[i, 1]-limits_s2_y[i, 0])\n",
    "    \n",
    "    limits_s2_m[i] = get_limits(samples_s2_m[:, :, :, :, i])\n",
    "    samples_s2_m[:, :, :, :, i] = (samples_s2_m[:, :, :, :, i]-limits_s2_m[i, 0])/(limits_s2_m[i, 1]-limits_s2_m[i, 0])\n",
    "\n",
    "# adjust remaining data beyond 0 and 1\n",
    "print('Adjusting data...')\n",
    "samples_s1_y[np.isnan(samples_s1_y)] = 1\n",
    "samples_s1_m[np.isnan(samples_s1_m)] = 1\n",
    "samples_s2_y[np.isnan(samples_s2_y)] = 0\n",
    "samples_s2_m[np.isnan(samples_s2_m)] = 0\n",
    "\n",
    "samples_s1_y[samples_s1_y>1] = 1\n",
    "samples_s1_y[samples_s1_y<0] = 0\n",
    "samples_s2_y[samples_s2_y>1] = 1\n",
    "samples_s2_y[samples_s2_y<0] = 0\n",
    "samples_s1_m[samples_s1_m>1] = 1\n",
    "samples_s1_m[samples_s1_m<0] = 0\n",
    "samples_s2_m[samples_s2_m>1] = 1\n",
    "samples_s2_m[samples_s2_m<0] = 0\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the prepared data\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_reference.npy', reference_cat)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s1_y.npy', samples_s1_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s2_y.npy', samples_s2_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s1_m.npy', samples_s1_m)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s2_m.npy', samples_s2_m)\n",
    "\n",
    "# save the limits for later use during prediction phase\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s1_y_limits.npy', limits_s1_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s2_y_limits.npy', limits_s2_y)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s1_m_limits.npy', limits_s1_m)\n",
    "np.save(f'/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/{samples_id}_PRO_s2_m_limits.npy', limits_s2_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to print some example samples\n",
    "\n",
    "# defines some colors to plor reference\n",
    "colors = [\"gray\", 'orange']\n",
    "cmap_custom = ListedColormap(colors)\n",
    "\n",
    "# a lil message\n",
    "print('Showing Some Samples')\n",
    "\n",
    "# loop to plot 5 rows of samples\n",
    "for i in range(5):\n",
    "    fig, ax = plt.subplots(1,4, sharey=True, sharex=True)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    sample = samples_s2_y[i*2, 92:-92, 92:-92, :]\n",
    "    r = sample[:,:,2]\n",
    "    g = sample[:,:,3]\n",
    "    b = sample[:,:,1]\n",
    "    ax[0].imshow(np.moveaxis(np.asarray([r,g,b]), 0, -1))\n",
    "    ax[1].imshow(reference[i*2], cmap=cmap_custom, vmin=-0.5, vmax=1.5, interpolation='nearest')\n",
    "    sample = samples_s2_y[i*2+1, 92:-92, 92:-92, :]\n",
    "    r = sample[:,:,2]\n",
    "    g = sample[:,:,3]\n",
    "    b = sample[:,:,1]\n",
    "    ax[2].imshow(np.moveaxis(np.asarray([r,g,b]), 0, -1))\n",
    "    ax[3].imshow(reference[i*2+1], cmap=cmap_custom, vmin=-0.5, vmax=1.5, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the limits for the curious mind\n",
    "print('Limits:')\n",
    "print(limits_s1_y)\n",
    "print(limits_s2_y)\n",
    "print(limits_s1_m)\n",
    "print(limits_s2_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of samples data from Sentinel-1 yearly reduction\n",
    "\n",
    "for i in range(len(bands_s1)):\n",
    "    plt.hist(samples_s1_y[:,:,:,i].ravel(), bins=100, alpha=.4, label=bands_s1[i])\n",
    "plt.legend()\n",
    "plt.title('Histogram - S1 Yearly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of samples data from Sentinel-2 yearly reduction\n",
    "\n",
    "for i in range(len(bands_s2)):\n",
    "    plt.hist(samples_s2_y[:,:,:,i].ravel(), bins=100, alpha=.4, label=bands_s2[i])\n",
    "plt.legend()\n",
    "plt.title('Histogram - S2 Yearly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of samples data from Sentinel-1 monthly reductions\n",
    "\n",
    "for i in range(len(bands_s1)):\n",
    "    plt.hist(samples_s1_m[:,:,:,:,i].ravel(), bins=100, alpha=.4, label=bands_s1[i])\n",
    "plt.legend()\n",
    "plt.title('Histogram - S1 Monthly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of samples data from Sentinel-2 monthly reductions\n",
    "\n",
    "for i in range(len(bands_s2)):\n",
    "    plt.hist(samples_s2_m[:,:,:,:,i].ravel(), bins=100, alpha=.4, label=bands_s2[i])\n",
    "plt.legend()\n",
    "plt.title('Histogram - S2 Monthly')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
