{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT 08: Prediction\n",
    "\n",
    "This is the eighth script in the methodology. Here, a model is used to generate the final classification map over all tiles. It can take a long time to complete. This script was created to let the user define which tiles need to be predicted upon, so that if the prediction stops before completion of all tiles, it can be restarted with only the remaining tiles. It also allows the prediction of only some test tiles before commiting the process to the whole study area.\n",
    "\n",
    "In the following cells, please refer to the comments in the code for further explanations of its functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import rasterio as r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the model number (id) an the iteration used for prediction\n",
    "model_num = 5\n",
    "iteration = 3\n",
    "\n",
    "# folder to save the predictions\n",
    "predictions_folder = f'/home/bruno.matosak/Semiarido/MultiInput/predictions/model_{str(model_num).zfill(2)}/iteration_{str(iteration).zfill(2)}'\n",
    "\n",
    "# creates the folder to save predictions, in case it still does not exist\n",
    "os.makedirs(predictions_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the limits from the samples used during training. it is very important that\n",
    "# these limits must match the limits used in the samples used to train the model.\n",
    "limits_s1_y = np.load('/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/5K_PRO_s1_y_limits.npy')\n",
    "limits_s2_y = np.load('/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/5K_PRO_s2_y_limits.npy')\n",
    "limits_s1_m = np.load('/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/5K_PRO_s1_m_limits.npy')\n",
    "limits_s2_m = np.load('/home/bruno.matosak/Semiarido/MultiInput/samples/sample_data/5K_PRO_s2_m_limits.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model and showing its layers\n",
    "model = tf.keras.models.load_model(f'/home/bruno.matosak/Semiarido/MultiInput/trainings/model_{str(model_num).zfill(2)}/iteration_{str(iteration).zfill(2)}/Model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, the prediction is made\n",
    "\n",
    "# defining the tiles to be predicted upon\n",
    "tiles = [  9,  10,  11,  13,  14,  15,  23,  24,  25,  26,\n",
    "          27,  28,  29,  30,  31,  32,  38,  39,  40,  41, \n",
    "          42,  43,  44,  45,  46,  47,  48,  51,  52,  53, \n",
    "          54,  55,  56,  57,  58,  59,  60,  61,  62,  63, \n",
    "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74, \n",
    "          75,  76,  77,  78,  79,  80,  81,  82,  83,  84, \n",
    "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94, \n",
    "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
    "         105, 106, 107, 108, 109, 110, 111, 113, 114, 115,\n",
    "         116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
    "         126, 127, 130, 131, 132, 133, 134, 135, 136, 137,\n",
    "         138, 139, 147, 148, 149, 150, 151, 152, 153, 154,\n",
    "         163, 164, 165, 166, 167, 168, 169, 179, 180, 181,\n",
    "         182, 183]\n",
    "\n",
    "# defining samples predefinintions. must match values used previously.\n",
    "chip_size = 254\n",
    "total_overlap = 186\n",
    "side_overlap = int(total_overlap/2)\n",
    "chip_util_size = chip_size-total_overlap\n",
    "\n",
    "# the number of samples to predict at every model.predict call.\n",
    "batch_size = 1000\n",
    "\n",
    "# looping through all tiles\n",
    "for tile in tqdm(tiles):\n",
    "    # do the prediction if the result file still does not exist.\n",
    "    if not os.path.exists(os.path.join(predictions_folder, f'result_id{str(tile).zfill(3)}.tif')):\n",
    "\n",
    "        # path to referemce to save file\n",
    "        ref_reduced = r.open(f'/home/bruno.matosak/Semiarido/MultiInput/yearly_reduction_S1/Reduction_SAR_Year_id{str(tile).zfill(3)}.tif').read(1)\n",
    "\n",
    "        # rows and columns of tile\n",
    "        i_size = int((ref_reduced.shape[0]-2*side_overlap)/chip_util_size)\n",
    "        j_size = int((ref_reduced.shape[1]-2*side_overlap)/chip_util_size)\n",
    "\n",
    "        # chips origins\n",
    "        origins = []\n",
    "        for i in range(i_size):\n",
    "            for j in range(j_size):\n",
    "                chip_check = ref_reduced[i*chip_util_size:i*chip_util_size+chip_size, j*chip_util_size:j*chip_util_size+chip_size]\n",
    "                if np.sum(chip_check==0)<chip_size*chip_size:\n",
    "                    origins.append([i*chip_util_size,j*chip_util_size])\n",
    "        origins = np.asarray(origins)\n",
    "\n",
    "        # load tile data\n",
    "        s1_y =  r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/yearly_reduction_S1/Reduction_SAR_Year_id{str(tile).zfill(3)}.tif\")\n",
    "        s2_y =  r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/yearly_reduction_S2/Reduction_Optical_Year_id{str(tile).zfill(3)}.tif\")\n",
    "        s1_m = [r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S1/Reduction_SAR_Months_id{str(tile).zfill(3)}_VV.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S1/Reduction_SAR_Months_id{str(tile).zfill(3)}_VH.tif\")]\n",
    "        s2_m = [r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B2.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B3.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B4.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B8.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B11.tif\"),\n",
    "                r.open(f\"/home/bruno.matosak/Semiarido/MultiInput/monthly_reduction_S2/Reduction_Optical_Months_id{str(tile).zfill(3)}_B12.tif\")]\n",
    "\n",
    "        # placeholder for prediction result\n",
    "        result = ref_reduced*0\n",
    "\n",
    "        # process data in batches\n",
    "        for i in range(0, len(origins), batch_size):\n",
    "            # origins for samples in batch\n",
    "            batch_origins = origins[i:i+batch_size]\n",
    "            bs = len(batch_origins)\n",
    "\n",
    "            # creates a placeholder to store the data to be predicted upon\n",
    "            chips_s1_y = np.zeros([bs, chip_size, chip_size, s1_y.count], dtype=np.float32)\n",
    "            chips_s2_y = np.zeros([bs, chip_size, chip_size, s2_y.count], dtype=np.float32)\n",
    "            chips_s1_m = np.zeros([bs, s1_m[0].count, chip_size, chip_size, len(s1_m)], dtype=np.float32)\n",
    "            chips_s2_m = np.zeros([bs, s2_m[0].count, chip_size, chip_size, len(s2_m)], dtype=np.float32)\n",
    "\n",
    "            # filling the placeholders - iterates through every sample origin\n",
    "            for ii in range(len(batch_origins)):\n",
    "                # creates the window to obtain data\n",
    "                w = r.windows.Window(batch_origins[ii][1], batch_origins[ii][0], chip_size, chip_size)\n",
    "                # filling S1 data\n",
    "                for j in range(len(s1_m)):\n",
    "                    chips_s1_m[ii, :, :, :, j] = s1_m[j].read(window=w)\n",
    "                chips_s1_y[ii, :, :, :] = np.moveaxis(s1_y.read(window=w), 0, -1)\n",
    "                # filling S2 data\n",
    "                for j in range(len(s2_m)):\n",
    "                    chips_s2_m[ii, :, :, :, j] = s2_m[j].read(window=w)\n",
    "                chips_s2_y[ii, :, :, :] = np.moveaxis(s2_y.read(window=w), 0, -1)\n",
    "\n",
    "            # scalling data according to limits defined during training\n",
    "            # S1\n",
    "            for ii in range(s1_y.count):\n",
    "                chips_s1_y[:,:,:,ii] = (chips_s1_y[:,:,:,ii]-limits_s1_y[ii,0])/(limits_s1_y[ii,1]-limits_s1_y[ii,0])\n",
    "                chips_s1_m[:,:,:,:,ii] = (chips_s1_m[:,:,:,:,ii]-limits_s1_m[ii,0])/(limits_s1_m[ii,1]-limits_s1_m[ii,0])\n",
    "\n",
    "            # S2\n",
    "            for ii in range(s2_y.count):\n",
    "                chips_s2_y[:,:,:,ii] = (chips_s2_y[:,:,:,ii]-limits_s2_y[ii,0])/(limits_s2_y[ii,1]-limits_s2_y[ii,0])\n",
    "                chips_s2_m[:,:,:,:,ii] = (chips_s2_m[:,:,:,:,ii]-limits_s2_m[ii,0])/(limits_s2_m[ii,1]-limits_s2_m[ii,0])\n",
    "\n",
    "            # correcting data limits\n",
    "            chips_s1_y[chips_s1_y>1] = 1\n",
    "            chips_s1_y[chips_s1_y<0] = 0\n",
    "            chips_s2_y[chips_s2_y>1] = 1\n",
    "            chips_s2_y[chips_s2_y<0] = 0\n",
    "            chips_s1_m[chips_s1_m>1] = 1\n",
    "            chips_s1_m[chips_s1_m<0] = 0\n",
    "            chips_s2_m[chips_s2_m>1] = 1\n",
    "            chips_s2_m[chips_s2_m<0] = 0\n",
    "\n",
    "            # doing the prediction\n",
    "            batch_predict = [chips_s1_y, chips_s2_y, chips_s1_m, chips_s2_m]\n",
    "            pred = model.predict(batch_predict, batch_size=25)\n",
    "            pred = tf.argmax(pred, -1)\n",
    "            for ii in range(len(pred)):\n",
    "                result[batch_origins[ii][0]+side_overlap:batch_origins[ii][0]+side_overlap+chip_util_size, batch_origins[ii][1]+side_overlap:batch_origins[ii][1]+side_overlap+chip_util_size] = pred[ii]\n",
    "\n",
    "        # Register GDAL format drivers and configuration options with a\n",
    "        # context manager.\n",
    "        with r.Env():\n",
    "\n",
    "            # Write an array as a raster band to a new 8-bit file. For\n",
    "            # the new file's profile, we start with the profile of the source\n",
    "            profile = s2_y.profile\n",
    "\n",
    "            # And then change the band count to 1, set the\n",
    "            # dtype to uint8, and specify LZW compression.\n",
    "            profile.update(\n",
    "                dtype=r.uint8,\n",
    "                count=1,\n",
    "                nodata=0)\n",
    "            \n",
    "            # opening file and writig data to it\n",
    "            with r.open(os.path.join(predictions_folder, f'result_id{str(tile).zfill(3)}.tif'), 'w', **profile) as dst:\n",
    "                dst.write(result.astype(r.uint8), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
